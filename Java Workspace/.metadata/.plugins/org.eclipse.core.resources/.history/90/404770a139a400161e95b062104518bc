//import home.laura.stanford-english-corenlp-2016-10-31-models;
import java.io.BufferedReader;
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.IOException;
import java.io.StringReader;
import java.util.List;

import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.process.*;
public class StartPoint {

	public static void main(String[] args) {
		Map<String, long> vocabulary = new HashMap<String, long>();
		 try {
			BufferedReader bufferReader = new BufferedReader(new FileReader(""));
			String currentLine;

			while ((currentLine = bufferReader.readLine()) != null) {
				System.out.println(currentLine);
			}
		} catch (Exception e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
		 String sent2 = "This is another sentence...";
		 TokenizerFactory<CoreLabel> tokenizerFactory =
				    PTBTokenizer.factory(new CoreLabelTokenFactory(), "");
	     List<CoreLabel> rawWords2 =
				    tokenizerFactory.getTokenizer(new StringReader(sent2)).tokenize();
		 System.out.println(rawWords2);		
	}
}
